# MANE-6962-Machine-Learning-Project
Image Segmentation and Classifcation Using Machine Learning Algorithms for the Purpose of Safe Drone Landing and Takeoff

This project concerns the safety of drone flight, as well as landing and takeoff procedures. Using an onboard camera, a drone can take images of the land below which can be processed by a machine learning algorithm to determine where is safe to land, or even what objects are beneath it. Using machine learning algorithms, the images can be segmented and classified into seperate parts that can influence the drone's landing procedure. If the classification is sufficent, this can be a leap forward for autonmous drone flight, as the drone itself can interpt its environment in order to determine the safe landing zones.

This project makes use of the Semantic Drone Dataset form the Institute of Computer Graphics and Vision at TU Graz University of Technology. This dataset contains 400 images of houses and other urban environments taken at altitudes of 5-30 meters off the ground. Each image is 6000x4000 pixels and feature a variety of objects and terrain. There are twenty different class labels such as "Tree", "Paved Area", "People" and more.

The goals of this project are to implement two machine learning algorithms to segment and classfiy these images. The first is a k nearest neighbors algorithm. This will be a baseline classification system used in order to gain an understanding of the dataset before moving on to a Convolutional Neural Network. The algorithms are planned to be used in two ways. The first will be to attempt to recreate the results provided as labeled images. These labeled images show what a 100% accurate segmentation and classification would look like, so the goal is to get the developed algorithms to match as close as possible. The second way these algorithms are planned to be used is a binary segmentation of "Safe" and "Not Safe" landing zones. Each given label will be assigned to one of the two binary options and the images will be reprocessed. Metrics such as improved accuracy or computational time will be measured to compare to the multi-class segmentation/classifaction.
