# MANE-6962-Machine-Learning-Project
Image Segmentation for Identification of Safe Landing Zones for Autonomous Drones

This project concerns the safety of drone flight, as well as landing and takeoff procedures. Using an onboard camera, a drone can take images of the land below which can be processed by a machine learning algorithm to determine where is safe to land, or even what objects are beneath it. Using machine learning algorithms, the images can be segmented and classified into seperate parts that can influence the drone's landing procedure. If the classification is sufficent, this can be a leap forward for autonmous drone flight, as the drone itself can interpt its environment in order to determine the safe landing zones.

This project makes use of the Semantic Drone Dataset form the Institute of Computer Graphics and Vision at TU Graz University of Technology. This dataset contains 400 images of houses and other urban environments taken at altitudes of 5-30 meters off the ground. Each image is 6000x4000 pixels and feature a variety of objects and terrain. There are twenty four different class labels such as "Tree", "Paved Area", "People" and more.

The goal of this project is to implement a machine learning algorithm to segment and classfiy these images. This algorithm is a convolutional neural network, specifically utilizing the Unet architecture. The segmentation and classification of each image is separated into a binary segmentation of "Safe for Landing" and "Not Safe for Landing" classes. Each of the given classes were sorted into one of the two binary super classes. Metrics such as accuracy and intersection over union score are then used to evaluate the performance of the model.
